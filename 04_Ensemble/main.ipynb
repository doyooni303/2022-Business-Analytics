{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does Ensemble really work well against single models on a real dataset?\n",
    "\n",
    "* In this tutorial, we are going to check whether getting ensemble, especially Bagging, with various types of single models work well compared to each single model.  \n",
    "\n",
    "* Models are for the binary classification.  \n",
    "\n",
    "* Single Models: Logistic Regression, KNN, Decision Tree, SVM\n",
    "\n",
    "* Ensemble : Getting hard or soft voting with the results of each single model\n",
    "\n",
    "* Moreover, we will get the result of Random Forest as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: Wine quality\n",
    "\n",
    "* Data is about classifying the quality of wine into good or bad\n",
    "\n",
    "* You can get the data from [here](https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "random_state = 42\n",
    "data = pd.read_csv('wine.csv')\n",
    "train, test = train_test_split(data,test_size=0.1,random_state=random_state,shuffle=True,stratify=data['quality'])\n",
    "x_train, y_train = train.iloc[:,:-1],train.iloc[:,-1]\n",
    "x_test, y_test = test.iloc[:,:-1],test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, '86'), Text(0, 0, '74')]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "bars=y_test.value_counts().plot(kind='bar', rot=0, color=['g','r'])\n",
    "plt.bar_label(bars.containers[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting each single models\n",
    "\n",
    "* To get the best result, parameter tuning by GridSearchCV will be done for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params,clf_reports,predictions,probs={},{},{},{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.78      0.61      0.68        74\n",
      "        good       0.72      0.85      0.78        86\n",
      "\n",
      "    accuracy                           0.74       160\n",
      "   macro avg       0.75      0.73      0.73       160\n",
      "weighted avg       0.74      0.74      0.73       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "parameters=dict(\n",
    "    penalty = ['elasticnet'],\n",
    "    max_iter=[1000],\n",
    "    C=[0.1,0.25,0.5,0.75],\n",
    "    solver = ['saga'],\n",
    "    n_jobs=[-1],\n",
    "    l1_ratio=[0,0.25,0.5,0.75,1.0]\n",
    ")\n",
    "\n",
    "logReg = LogisticRegression()\n",
    "clf = GridSearchCV(\n",
    "    logReg,\n",
    "    parameters\n",
    ").fit(x_train,y_train)\n",
    "best_params['logReg']=clf.best_params_\n",
    "y_predict = clf.predict(x_test)\n",
    "predictions['logReg']=y_predict\n",
    "y_prob = clf.predict_proba(x_test)\n",
    "probs['logReg'] = y_prob\n",
    "clf_reports['logReg']=classification_report(y_test,y_predict)\n",
    "print(clf_reports['logReg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.78      0.73      0.76        74\n",
      "        good       0.78      0.83      0.80        86\n",
      "\n",
      "    accuracy                           0.78       160\n",
      "   macro avg       0.78      0.78      0.78       160\n",
      "weighted avg       0.78      0.78      0.78       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "parameters = dict(\n",
    "    n_neighbors=[3,5,7,9],\n",
    "    weights=['uniform','distance'],\n",
    "    p=[1,2],\n",
    ")\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    knn,\n",
    "    parameters\n",
    ").fit(x_train,y_train)\n",
    "best_params['knn'] = clf.best_params_\n",
    "y_predict = clf.predict(x_test)\n",
    "predictions['knn']=y_predict\n",
    "y_prob = clf.predict_proba(x_test)\n",
    "probs['knn'] = y_prob\n",
    "clf_reports['knn']=classification_report(y_test,y_predict)\n",
    "print(clf_reports['knn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.80      0.77      0.79        74\n",
      "        good       0.81      0.84      0.82        86\n",
      "\n",
      "    accuracy                           0.81       160\n",
      "   macro avg       0.81      0.80      0.80       160\n",
      "weighted avg       0.81      0.81      0.81       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "parameters=dict(\n",
    "    criterion=['gini','entropy','log_loss'],\n",
    "    max_features=['sqrt','log2'],\n",
    "    random_state=[1,2,3],\n",
    "\n",
    ")\n",
    "dt = DecisionTreeClassifier()\n",
    "clf = GridSearchCV(\n",
    "    dt,\n",
    "    parameters\n",
    ").fit(x_train,y_train)\n",
    "best_params['dt'] = clf.best_params_\n",
    "y_predict = clf.predict(x_test)\n",
    "predictions['dt']=y_predict\n",
    "y_prob = clf.predict_proba(x_test)\n",
    "probs['dt'] = y_prob\n",
    "clf_reports['dt']=classification_report(y_test,y_predict)\n",
    "print(clf_reports['dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.73      0.73      0.73        74\n",
      "        good       0.77      0.77      0.77        86\n",
      "\n",
      "    accuracy                           0.75       160\n",
      "   macro avg       0.75      0.75      0.75       160\n",
      "weighted avg       0.75      0.75      0.75       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "parameters = dict(\n",
    "    C=[0.1,0.5,0.8,1.0],\n",
    "    kernel=['linear','poly','rbf'],\n",
    "    probability=[True],\n",
    "    coef0=[0,0.3,0.5]\n",
    ")\n",
    "svm = SVC()\n",
    "clf = GridSearchCV(\n",
    "    svm,\n",
    "    parameters\n",
    ").fit(x_train,y_train)\n",
    "best_params['svm'] = clf.best_params_\n",
    "y_predict = clf.predict(x_test)\n",
    "predictions['svm']=y_predict\n",
    "y_prob = clf.predict_proba(x_test)\n",
    "probs['svm'] = y_prob\n",
    "clf_reports['svm']=classification_report(y_test,y_predict)\n",
    "print(clf_reports['svm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logReg</th>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.729207</td>\n",
       "      <td>0.810182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.778752</td>\n",
       "      <td>0.862665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.804532</td>\n",
       "      <td>0.803740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.748586</td>\n",
       "      <td>0.815839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            acc        f1   roc_auc\n",
       "logReg  0.73750  0.729207  0.810182\n",
       "knn     0.78125  0.778752  0.862665\n",
       "dt      0.80625  0.804532  0.803740\n",
       "svm     0.75000  0.748586  0.815839"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score,f1_score,accuracy_score\n",
    "\n",
    "scores = {}\n",
    "for model in ['logReg','knn','dt','svm']:\n",
    "    scores[model]={\n",
    "        'acc':accuracy_score(y_test,predictions[model]),\n",
    "        'f1':f1_score(y_test,predictions[model],average='macro'),\n",
    "        'roc_auc':roc_auc_score(y_test,probs[model][:,1])\n",
    "    }\n",
    "scores = pd.DataFrame(scores).transpose()\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As the results, Decision Tree got the best results on the accuracy and f1 scores, however, its roc_auc score was the lowest.\n",
    "\n",
    "* It seems that KNN works pretty well as a single model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble: Voting\n",
    "\n",
    "* Now, we are going to get the result of voting from each single model with the best parameters found by GridSearch.\n",
    "\n",
    "* There are two options: Hard voting, Soft voting  \n",
    "    Since Hard voting gets the results with predicted labels, it is hard to get roc_auc scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.8125, 'f1': 0.8120300751879699}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensemble_results={}\n",
    "ens_hard = VotingClassifier(\n",
    "    estimators=[('logReg',LogisticRegression(**best_params['logReg'])),\n",
    "                ('knn',KNeighborsClassifier(**best_params['knn'])),\n",
    "                ('dt',DecisionTreeClassifier(**best_params['dt'])),\n",
    "                ('svm',SVC(**best_params['svm']))\n",
    "    ],\n",
    "    voting = 'hard'\n",
    ").fit(x_train,y_train)\n",
    "\n",
    "\n",
    "ensemble_results['ens_hard']={\n",
    "        'acc':accuracy_score(y_test,ens_hard.predict(x_test)),\n",
    "        'f1':f1_score(y_test,ens_hard.predict(x_test),average='macro'),\n",
    "        #'roc_auc':roc_auc_score(y_test,ens_diff_hard.predict_proba(x_test))\n",
    "    }\n",
    "ensemble_results['ens_hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.8375, 'f1': 0.8349206349206348, 'roc_auc': 0.899277184160905}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens_soft = VotingClassifier(\n",
    "    estimators=[('logReg',LogisticRegression(**best_params['logReg'])),\n",
    "                ('knn',KNeighborsClassifier(**best_params['knn'])),\n",
    "                ('dt',DecisionTreeClassifier(**best_params['dt'])),\n",
    "                ('svm',SVC(**best_params['svm']))\n",
    "    ],\n",
    "    voting = 'soft'\n",
    ").fit(x_train,y_train)\n",
    "\n",
    "\n",
    "ensemble_results['ens_soft']={\n",
    "        'acc':accuracy_score(y_test,ens_soft.predict(x_test)),\n",
    "        'f1':f1_score(y_test,ens_soft.predict(x_test),average='macro'),\n",
    "        'roc_auc':roc_auc_score(y_test,ens_soft.predict_proba(x_test)[:,1])\n",
    "    }\n",
    "ensemble_results['ens_soft']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final score\n",
    "\n",
    "* Here is the final scores of single models and hard/soft voting of each single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logReg</th>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.729207</td>\n",
       "      <td>0.810182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.778752</td>\n",
       "      <td>0.862665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.804532</td>\n",
       "      <td>0.803740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.748586</td>\n",
       "      <td>0.815839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ens_hard</th>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ens_soft</th>\n",
       "      <td>0.83750</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.899277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              acc        f1   roc_auc\n",
       "logReg    0.73750  0.729207  0.810182\n",
       "knn       0.78125  0.778752  0.862665\n",
       "dt        0.80625  0.804532  0.803740\n",
       "svm       0.75000  0.748586  0.815839\n",
       "ens_hard  0.81250  0.812030       NaN\n",
       "ens_soft  0.83750  0.834921  0.899277"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores = scores.append(pd.DataFrame(ensemble_results).transpose())\n",
    "final_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is really interesting that Ensemble really works well!  \n",
    "\n",
    "* Both types of voting(Hard,Soft) are better than any other single models in terms of Accuracy and F1 scores.  \n",
    "\n",
    "* Especially, Soft voting made the best results of all the metrics.\n",
    "\n",
    "* When it comes to Ensemble, it takes two important things: Diversity, Accuracy  \n",
    "    - Each baselearner should be different to each other.  \n",
    "    - Of course, they should do well.  \n",
    "\n",
    "* Since the ensemble we did above satifies these two conidtions, it made the best results.  \n",
    "\n",
    "* Then, what if we do the voting with the one type of model with different parameters?  \n",
    "    In this case, we are going to check with Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.7875, 'f1': 0.786967418546366}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_params=dict(\n",
    "    dt1={'criterion':'gini','splitter':'best','max_features':'sqrt','random_state':1,},\n",
    "    dt2={'criterion':'gini','splitter':'random','max_features':'sqrt','random_state':2,},\n",
    "    dt3={'criterion':'entropy','splitter':'best','max_features':'log2','random_state':3,},\n",
    "    dt4={'criterion':'entropy','splitter':'random','max_features':'sqrt','random_state':4,},\n",
    ")\n",
    "\n",
    "ens_dt_hard = VotingClassifier(\n",
    "    estimators=[('dt1',DecisionTreeClassifier(**dt_params['dt1'])),\n",
    "                ('dt2',DecisionTreeClassifier(**dt_params['dt2'])),\n",
    "                ('dt3',DecisionTreeClassifier(**dt_params['dt3'])),\n",
    "                ('dt4',DecisionTreeClassifier(**dt_params['dt4'])),\n",
    "    ],\n",
    "    voting = 'hard'\n",
    ").fit(x_train,y_train)\n",
    "\n",
    "\n",
    "ensemble_results['ens_dt_hard']={\n",
    "        'acc':accuracy_score(y_test,ens_dt_hard.predict(x_test)),\n",
    "        'f1':f1_score(y_test,ens_dt_hard.predict(x_test),average='macro'),\n",
    "        #'roc_auc':roc_auc_score(y_test,ens_soft.predict_proba(x_test)[:,1])\n",
    "    }\n",
    "ensemble_results['ens_dt_hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.7875, 'f1': 0.786967418546366, 'roc_auc': 0.8819924575738529}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_params=dict(\n",
    "    dt1={'criterion':'gini','splitter':'best','max_features':'sqrt','random_state':1,},\n",
    "    dt2={'criterion':'gini','splitter':'random','max_features':'sqrt','random_state':2,},\n",
    "    dt3={'criterion':'entropy','splitter':'best','max_features':'log2','random_state':3,},\n",
    "    dt4={'criterion':'entropy','splitter':'random','max_features':'sqrt','random_state':4,},\n",
    ")\n",
    "\n",
    "ens_dt_soft = VotingClassifier(\n",
    "    estimators=[('dt1',DecisionTreeClassifier(**dt_params['dt1'])),\n",
    "                ('dt2',DecisionTreeClassifier(**dt_params['dt2'])),\n",
    "                ('dt3',DecisionTreeClassifier(**dt_params['dt3'])),\n",
    "                ('dt4',DecisionTreeClassifier(**dt_params['dt4'])),\n",
    "    ],\n",
    "    voting = 'soft'\n",
    ").fit(x_train,y_train)\n",
    "\n",
    "\n",
    "ensemble_results['ens_dt_soft']={\n",
    "        'acc':accuracy_score(y_test,ens_dt_soft.predict(x_test)),\n",
    "        'f1':f1_score(y_test,ens_dt_soft.predict(x_test),average='macro'),\n",
    "        'roc_auc':roc_auc_score(y_test,ens_dt_soft.predict_proba(x_test)[:,1])\n",
    "    }\n",
    "ensemble_results['ens_dt_soft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logReg</th>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.729207</td>\n",
       "      <td>0.810182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.778752</td>\n",
       "      <td>0.862665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.804532</td>\n",
       "      <td>0.803740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.748586</td>\n",
       "      <td>0.815839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ens_hard</th>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ens_soft</th>\n",
       "      <td>0.83750</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.899277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ens_dt_hard</th>\n",
       "      <td>0.78750</td>\n",
       "      <td>0.786967</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ens_dt_soft</th>\n",
       "      <td>0.78750</td>\n",
       "      <td>0.786967</td>\n",
       "      <td>0.881992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 acc        f1   roc_auc\n",
       "logReg       0.73750  0.729207  0.810182\n",
       "knn          0.78125  0.778752  0.862665\n",
       "dt           0.80625  0.804532  0.803740\n",
       "svm          0.75000  0.748586  0.815839\n",
       "ens_hard     0.81250  0.812030       NaN\n",
       "ens_soft     0.83750  0.834921  0.899277\n",
       "ens_dt_hard  0.78750  0.786967       NaN\n",
       "ens_dt_soft  0.78750  0.786967  0.881992"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores = scores.append(pd.DataFrame(ensemble_results).transpose())\n",
    "final_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we can see, making ensemble with only one type of model is not that good, which means diversity does matter for the ensemble.\n",
    "\n",
    "* Then, what about doing Bagging instead of just simple voting with one type of model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logReg</th>\n",
       "      <td>0.73750</td>\n",
       "      <td>0.729207</td>\n",
       "      <td>0.810182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.778752</td>\n",
       "      <td>0.862665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.80625</td>\n",
       "      <td>0.804532</td>\n",
       "      <td>0.803740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.748586</td>\n",
       "      <td>0.815839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ens_hard</th>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.812030</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ens_soft</th>\n",
       "      <td>0.83750</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.899277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ens_dt_hard</th>\n",
       "      <td>0.78750</td>\n",
       "      <td>0.786967</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ens_dt_soft</th>\n",
       "      <td>0.78750</td>\n",
       "      <td>0.786967</td>\n",
       "      <td>0.881992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagging_dt</th>\n",
       "      <td>0.78750</td>\n",
       "      <td>0.787201</td>\n",
       "      <td>0.868636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 acc        f1   roc_auc\n",
       "logReg       0.73750  0.729207  0.810182\n",
       "knn          0.78125  0.778752  0.862665\n",
       "dt           0.80625  0.804532  0.803740\n",
       "svm          0.75000  0.748586  0.815839\n",
       "ens_hard     0.81250  0.812030       NaN\n",
       "ens_soft     0.83750  0.834921  0.899277\n",
       "ens_dt_hard  0.78750  0.786967       NaN\n",
       "ens_dt_soft  0.78750  0.786967  0.881992\n",
       "bagging_dt   0.78750  0.787201  0.868636"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging_clf = BaggingClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(**best_params['dt']),\n",
    "    n_estimators = 4,\n",
    "    random_state = 1\n",
    "    ).fit(x_train,y_train)\n",
    "\n",
    "ensemble_results['bagging_dt']={\n",
    "        'acc':accuracy_score(y_test,bagging_clf.predict(x_test)),\n",
    "        'f1':f1_score(y_test,bagging_clf.predict(x_test),average='macro'),\n",
    "        'roc_auc':roc_auc_score(y_test,bagging_clf.predict_proba(x_test)[:,1])\n",
    "    }\n",
    "\n",
    "scores.append(pd.DataFrame(ensemble_results).transpose())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Bagging in this case did not work well compared to the votings.\n",
    "\n",
    "* As as a result, soft voting can be a better option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data: Breast cancer diagnosis\n",
    "\n",
    "* Let's do the whole process again with another dataset which is breast cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer(as_frame=True)\n",
    "x_train,x_test,y_train,y_test = train_test_split(data['data'],data['target'],test_size=0.2, random_state=random_state,stratify=data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting each single models\n",
    "\n",
    "* To get the best result, parameter tuning by GridSearchCV will be done for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params,clf_reports,predictions,probs={},{},{},{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91        42\n",
      "           1       0.93      0.97      0.95        72\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.93       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "parameters=dict(\n",
    "    penalty = ['elasticnet'],\n",
    "    max_iter=[1000],\n",
    "    C=[0.1,0.25,0.5,0.75],\n",
    "    solver = ['saga'],\n",
    "    n_jobs=[-1],\n",
    "    l1_ratio=[0,0.25,0.5,0.75,1.0]\n",
    ")\n",
    "\n",
    "logReg = LogisticRegression()\n",
    "clf = GridSearchCV(\n",
    "    logReg,\n",
    "    parameters\n",
    ").fit(x_train,y_train)\n",
    "best_params['logReg']=clf.best_params_\n",
    "y_predict = clf.predict(x_test)\n",
    "predictions['logReg']=y_predict\n",
    "y_prob = clf.predict_proba(x_test)\n",
    "probs['logReg'] = y_prob\n",
    "clf_reports['logReg']=classification_report(y_test,y_predict)\n",
    "print(clf_reports['logReg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        42\n",
      "           1       0.94      0.94      0.94        72\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "parameters = dict(\n",
    "    n_neighbors=[3,5,7,9],\n",
    "    weights=['uniform','distance'],\n",
    "    p=[1,2],\n",
    ")\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    knn,\n",
    "    parameters\n",
    ").fit(x_train,y_train)\n",
    "best_params['knn'] = clf.best_params_\n",
    "y_predict = clf.predict(x_test)\n",
    "predictions['knn']=y_predict\n",
    "y_prob = clf.predict_proba(x_test)\n",
    "probs['knn'] = y_prob\n",
    "clf_reports['knn']=classification_report(y_test,y_predict)\n",
    "print(clf_reports['knn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89        42\n",
      "           1       0.96      0.90      0.93        72\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.90      0.92      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "parameters=dict(\n",
    "    criterion=['gini','entropy','log_loss'],\n",
    "    max_features=['sqrt','log2'],\n",
    "    random_state=[1,2,3],\n",
    "\n",
    ")\n",
    "dt = DecisionTreeClassifier()\n",
    "clf = GridSearchCV(\n",
    "    dt,\n",
    "    parameters\n",
    ").fit(x_train,y_train)\n",
    "best_params['dt'] = clf.best_params_\n",
    "y_predict = clf.predict(x_test)\n",
    "predictions['dt']=y_predict\n",
    "y_prob = clf.predict_proba(x_test)\n",
    "probs['dt'] = y_prob\n",
    "clf_reports['dt']=classification_report(y_test,y_predict)\n",
    "print(clf_reports['dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.94        42\n",
      "           1       0.95      0.99      0.97        72\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "parameters = dict(\n",
    "    C=[0.1,0.5,0.8,1.0],\n",
    "    kernel=['linear','poly','rbf'],\n",
    "    probability=[True],\n",
    "    coef0=[0,0.3,0.5]\n",
    ")\n",
    "svm = SVC()\n",
    "clf = GridSearchCV(\n",
    "    svm,\n",
    "    parameters\n",
    ").fit(x_train,y_train)\n",
    "best_params['svm'] = clf.best_params_\n",
    "y_predict = clf.predict(x_test)\n",
    "predictions['svm']=y_predict\n",
    "y_prob = clf.predict_proba(x_test)\n",
    "probs['svm'] = y_prob\n",
    "clf_reports['svm']=classification_report(y_test,y_predict)\n",
    "print(clf_reports['svm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logReg</th>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.932981</td>\n",
       "      <td>0.950066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.924603</td>\n",
       "      <td>0.965939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.907468</td>\n",
       "      <td>0.915675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.952129</td>\n",
       "      <td>0.996362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             acc        f1   roc_auc\n",
       "logReg  0.938596  0.932981  0.950066\n",
       "knn     0.929825  0.924603  0.965939\n",
       "dt      0.912281  0.907468  0.915675\n",
       "svm     0.956140  0.952129  0.996362"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score,f1_score,accuracy_score\n",
    "\n",
    "scores = {}\n",
    "for model in ['logReg','knn','dt','svm']:\n",
    "    scores[model]={\n",
    "        'acc':accuracy_score(y_test,predictions[model]),\n",
    "        'f1':f1_score(y_test,predictions[model],average='macro'),\n",
    "        'roc_auc':roc_auc_score(y_test,probs[model][:,1])\n",
    "    }\n",
    "scores = pd.DataFrame(scores).transpose()\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For this dataset, SVM get the best result with all the metrics.\n",
    "\n",
    "* Other single models work well as they show at least 0.9 in f1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble: Voting\n",
    "\n",
    "* Now, we are going to get the result of voting from each single model with the best parameters found by GridSearch.\n",
    "\n",
    "* There are two options: Hard voting, Soft voting  \n",
    "    Since Hard voting gets the results with predicted labels, it is hard to get roc_auc scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.9473684210526315, 'f1': 0.9434523809523809}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensemble_results={}\n",
    "ens_hard = VotingClassifier(\n",
    "    estimators=[('logReg',LogisticRegression(**best_params['logReg'])),\n",
    "                ('knn',KNeighborsClassifier(**best_params['knn'])),\n",
    "                ('dt',DecisionTreeClassifier(**best_params['dt'])),\n",
    "                ('svm',SVC(**best_params['svm']))\n",
    "    ],\n",
    "    voting = 'hard'\n",
    ").fit(x_train,y_train)\n",
    "\n",
    "\n",
    "ensemble_results['ens_hard']={\n",
    "        'acc':accuracy_score(y_test,ens_hard.predict(x_test)),\n",
    "        'f1':f1_score(y_test,ens_hard.predict(x_test),average='macro'),\n",
    "        #'roc_auc':roc_auc_score(y_test,ens_diff_hard.predict_proba(x_test))\n",
    "    }\n",
    "ensemble_results['ens_hard']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.9385964912280702,\n",
       " 'f1': 0.9329805996472663,\n",
       " 'roc_auc': 0.9900793650793651}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens_soft = VotingClassifier(\n",
    "    estimators=[('logReg',LogisticRegression(**best_params['logReg'])),\n",
    "                ('knn',KNeighborsClassifier(**best_params['knn'])),\n",
    "                ('dt',DecisionTreeClassifier(**best_params['dt'])),\n",
    "                ('svm',SVC(**best_params['svm']))\n",
    "    ],\n",
    "    voting = 'soft'\n",
    ").fit(x_train,y_train)\n",
    "\n",
    "\n",
    "ensemble_results['ens_soft']={\n",
    "        'acc':accuracy_score(y_test,ens_soft.predict(x_test)),\n",
    "        'f1':f1_score(y_test,ens_soft.predict(x_test),average='macro'),\n",
    "        'roc_auc':roc_auc_score(y_test,ens_soft.predict_proba(x_test)[:,1])\n",
    "    }\n",
    "ensemble_results['ens_soft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logReg</th>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.932981</td>\n",
       "      <td>0.950066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.929825</td>\n",
       "      <td>0.924603</td>\n",
       "      <td>0.965939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.907468</td>\n",
       "      <td>0.915675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>0.956140</td>\n",
       "      <td>0.952129</td>\n",
       "      <td>0.996362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ens_hard</th>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.943452</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ens_soft</th>\n",
       "      <td>0.938596</td>\n",
       "      <td>0.932981</td>\n",
       "      <td>0.990079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               acc        f1   roc_auc\n",
       "logReg    0.938596  0.932981  0.950066\n",
       "knn       0.929825  0.924603  0.965939\n",
       "dt        0.912281  0.907468  0.915675\n",
       "svm       0.956140  0.952129  0.996362\n",
       "ens_hard  0.947368  0.943452       NaN\n",
       "ens_soft  0.938596  0.932981  0.990079"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores = scores.append(pd.DataFrame(ensemble_results).transpose())\n",
    "final_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For this dataset, soft voting is not better than the best single model SVM.  \n",
    "    Hard voting made better performances than soft voting on the scores of accuracy and f1.\n",
    "\n",
    "* However, the results with votings are better than any other single models except SVM.\n",
    "\n",
    "* Still, it is worth to try votings for finding better results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
